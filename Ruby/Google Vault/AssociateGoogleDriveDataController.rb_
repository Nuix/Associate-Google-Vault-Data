class AssociateGoogleDriveDataController

	# Escapes certain characters in a value that would potentially cause a search to be invalid
	# it is important to note that just because a character is escaped does not mean Nuix will search for it.
	# For example if I am search the name field for:
	# name:"Its \"that\" day again"
	# Escaping the quotes may help prevent this search from having an error but does not necessarily mean that
	# the search now matches on quotes.
	def escape_for_search(value)
		return value.encode("utf-8")
			.gsub("\\","\\\\\\") #Escape \
			.gsub("?","\\?") #Escape ?
			.gsub("*","\\*") #Escape *
			.gsub("\"","\\\"") #Escape "
			.gsub("\u201C".encode("utf-8"),"\\\u201C".encode("utf-8")) #Escape left smart quote
			.gsub("\u201D".encode("utf-8"),"\\\u201D".encode("utf-8")) #Escape right smart quote
			.gsub("'","\\\\'") #Escape '
			.gsub("{","\\{")
			.gsub("}","\\}")
	end

	def handleData(pd, values)
		
		script_directory = File.dirname(__FILE__)

		# Load class for parsing XML
		load File.join(script_directory,"GoogleXmlObjects.rb_")
		# Load logging class
		load File.join(script_directory,"Logger.rb_")

		# We will need this to parse the DateTime values from the XML
		java_import "org.joda.time.format.DateTimeFormat"

		# Define the date time format used to convert "Tag" nodes with a "TagDataType" of "DateTime"
		# to an actual Joda DateTime object before storing as custom metadata
		# http://joda-time.sourceforge.net/apidocs/org/joda/time/format/DateTimeFormat.html
		date_time_format_pattern = "yyyy-MM-dd'T'HH:mm:ss.SSSZ"

		# Build pattern for parsing DateTime values in "Tag" nodes
		date_time_format = DateTimeFormat.forPattern(date_time_format_pattern)

		tag_prefix = values["tag_prefix"]
		xml_file_paths = values["xml_file_paths"]
		apply_label_tags = values["apply_label_tags"]

		# Track errors, warnings, successes and start time
		error_count = 0
		warning_count = 0
		match_count = 0
		start_time = Time.now

		pd.setTitle("Associate Google Drive Data")
		pd.setSubStatus("Errors: #{error_count}, Warnings: #{warning_count}, Matches: #{match_count}")

		# Parse 'Document' nodes from XML files user specified
		pd.setMainStatusAndLogIt("Parsing XML files...")
		data = GoogleXmlData.new
		xml_file_paths.each do |xml_file_path|
			pd.logMessage("Parsing: #{xml_file_path}")
			begin
				data.parse_xml_file(xml_file_path)
			rescue Exception => exc
				pd.logMessage("!!! Error while parsing XML file '#{xml_file_path}':")
				pd.logMessage(exc.message)
				error_count += 1
				pd.setSubStatus("Errors: #{error_count}, Warnings: #{warning_count}, Matches: #{match_count}")
			end
		end

		pd.logMessage("Total Document Nodes Parsed: #{data.total_documents}")
		pd.logMessage("Distinct 'TagName' Values:")
		data.distinct_tag_names.each do |name|
			pd.logMessage("\t#{name}")
		end

		# We are going to group matches items by the labels associated to those
		# items in the XML file.  We group them up so we can tag in batches
		grouped_by_label = Hash.new{|h,k|h[k]=[]}

		data.each_document do |document|
			external_file_name = document.external_file_name
			escaped_external_file_name = escape_for_search(external_file_name)
			items = $current_case.searchUnsorted("name:\"#{escaped_external_file_name}\"")
			if items.size < 1
				pd.logMessage("Unable to locate item with name: #{external_file_name}")
				warning_count += 1
				pd.setSubStatus("Errors: #{error_count}, Warnings: #{warning_count}, Matches: #{match_count}")
			else
				document.annotate_items(items,date_time_format)
				# Record DocID
				document.record_docid(items)
				match_count += 1
				pd.setSubStatus("Errors: #{error_count}, Warnings: #{warning_count}, Matches: #{match_count}")
				# Group item by labels associated in XML data
				labels = document.labels
				items.each do |item|
					labels.each do |label|
						grouped_by_label[label] << item
					end
				end
			end
		end
		
		# Apply labels as tags using groups so we perform fewer tagging operations
		if apply_label_tags
			pd.setMainStatusAndLogIt("Applying Labels as Tags...")
			annotater = $utilities.getBulkAnnotater
			grouped_by_label.each do |label,items|
				tag = "#{tag_prefix}|#{label}"
				pd.logMessage("\tApplying label '#{label}' as tag '#{tag}' to #{items.size} items...")
				annotater.addTag(tag,items)
			end
		end

		# We are done!
		pd.setMainStatusAndLogIt("Completed #{Time.at(Time.now - start_time).gmtime.strftime("%H:%M:%S")}")
		pd.setMainProgress(1,1)
		pd.setSubStatusAndLogIt("Errors: #{error_count}, Warnings: #{warning_count}, Matches: #{match_count}")

	end
end